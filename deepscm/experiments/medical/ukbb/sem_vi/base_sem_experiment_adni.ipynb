{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('/home/aay993/dscm/DSCM_implementation/')\n",
    "\n",
    "import pyro\n",
    "\n",
    "from typing import Mapping\n",
    "\n",
    "from pyro.infer import SVI, TraceGraph_ELBO\n",
    "from pyro.nn import pyro_method\n",
    "from pyro.optim import Adam\n",
    "from torch.distributions import Independent\n",
    "\n",
    "import torch\n",
    "from pyro.distributions.torch_transform import ComposeTransformModule\n",
    "from pyro.distributions.transforms import (\n",
    "    ComposeTransform, AffineTransform, ExpTransform, Spline\n",
    ")\n",
    "from pyro.distributions import LowRankMultivariateNormal, MultivariateNormal, Normal, TransformedDistribution\n",
    "from deepscm.arch.medical import Decoder, Encoder\n",
    "from deepscm.distributions.transforms.reshape import ReshapeTransform\n",
    "from deepscm.distributions.transforms.affine import LowerCholeskyAffine\n",
    "\n",
    "from deepscm.distributions.deep import DeepMultivariateNormal, DeepIndepNormal, Conv2dIndepNormal, DeepLowRankMultivariateNormal\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from deepscm.experiments.medical.base_experiment_adni import BaseCovariateExperiment, BaseSEM, EXPERIMENT_REGISTRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "\n",
    "from typing import Mapping\n",
    "\n",
    "from pyro.infer import SVI, TraceGraph_ELBO\n",
    "from pyro.nn import pyro_method\n",
    "from pyro.optim import Adam\n",
    "from torch.distributions import Independent\n",
    "\n",
    "import torch\n",
    "from pyro.distributions.torch_transform import ComposeTransformModule\n",
    "from pyro.distributions.transforms import (\n",
    "    ComposeTransform, AffineTransform, ExpTransform, Spline\n",
    ")\n",
    "from pyro.distributions import LowRankMultivariateNormal, MultivariateNormal, Normal, TransformedDistribution\n",
    "from deepscm.arch.medical import Decoder, Encoder\n",
    "from deepscm.distributions.transforms.reshape import ReshapeTransform\n",
    "from deepscm.distributions.transforms.affine import LowerCholeskyAffine\n",
    "\n",
    "from deepscm.distributions.deep import DeepMultivariateNormal, DeepIndepNormal, Conv2dIndepNormal, DeepLowRankMultivariateNormal\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from deepscm.experiments.medical.base_experiment_adni import BaseCovariateExperiment, BaseSEM, EXPERIMENT_REGISTRY\n",
    "\n",
    "class CustomELBO(TraceGraph_ELBO):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.trace_storage = {'model': None, 'guide': None}\n",
    "\n",
    "    def _get_trace(self, model, guide, args, kwargs):\n",
    "        model_trace, guide_trace = super()._get_trace(model, guide, args, kwargs)\n",
    "\n",
    "        self.trace_storage['model'] = model_trace\n",
    "        self.trace_storage['guide'] = guide_trace\n",
    "\n",
    "        return model_trace, guide_trace\n",
    "\n",
    "\n",
    "class Lambda(torch.nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.func(x)\n",
    "\n",
    "class BaseVISEM(BaseSEM):\n",
    "    context_dim = 0 # number of context dimensions for decoder \n",
    "\n",
    "    def __init__(self, latent_dim: int, logstd_init: float = -5, enc_filters: str = '16,32,64,128', dec_filters: str = '128,64,32,16',\n",
    "                 num_convolutions: int = 2, use_upconv: bool = False, decoder_type: str = 'fixed_var', decoder_cov_rank: int = 10, eps=0.01, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.img_shape = (1, 192 // self.downsample, 192 // self.downsample) if self.downsample > 0 else (1, 192, 192)\n",
    "\n",
    "        self.latent_dim = latent_dim\n",
    "        self.logstd_init = logstd_init\n",
    "\n",
    "        self.enc_filters = tuple(int(f.strip()) for f in enc_filters.split(','))\n",
    "        self.dec_filters = tuple(int(f.strip()) for f in dec_filters.split(','))\n",
    "        self.num_convolutions = num_convolutions\n",
    "        self.use_upconv = use_upconv\n",
    "        self.decoder_type = decoder_type\n",
    "        self.decoder_cov_rank = decoder_cov_rank\n",
    "\n",
    "        # decoder parts \n",
    "        decoder = Decoder(\n",
    "            num_convolutions=self.num_convolutions, filters=self.dec_filters,\n",
    "            latent_dim=self.latent_dim + self.context_dim, upconv=self.use_upconv,\n",
    "            output_size=self.img_shape\n",
    "            )\n",
    "\n",
    "        if self.decoder_type == 'fixed_var':\n",
    "            self.decoder = Conv2dIndepNormal(decoder, 1, 1)\n",
    "\n",
    "            torch.nn.init.zeros_(self.decoder.logvar_head.weight)\n",
    "            self.decoder.logvar_head.weight.requires_grad = False\n",
    "\n",
    "            torch.nn.init.constant_(self.decoder.logvar_head.bias, self.logstd_init)\n",
    "            self.decoder.logvar_head.bias.requires_grad = False\n",
    "        elif self.decoder_type == 'learned_var':\n",
    "            self.decoder = Conv2dIndepNormal(decoder, 1, 1)\n",
    "\n",
    "            torch.nn.init.zeros_(self.decoder.logvar_head.weight)\n",
    "            self.decoder.logvar_head.weight.requires_grad = False\n",
    "\n",
    "            torch.nn.init.constant_(self.decoder.logvar_head.bias, self.logstd_init)\n",
    "            self.decoder.logvar_head.bias.requires_grad = True\n",
    "        elif self.decoder_type == 'independent_gaussian':\n",
    "            self.decoder = Conv2dIndepNormal(decoder, 1, 1)\n",
    "\n",
    "            torch.nn.init.zeros_(self.decoder.logvar_head.weight)\n",
    "            self.decoder.logvar_head.weight.requires_grad = True\n",
    "\n",
    "            torch.nn.init.normal_(self.decoder.logvar_head.bias, self.logstd_init, 1e-1)\n",
    "            self.decoder.logvar_head.bias.requires_grad = True\n",
    "        elif self.decoder_type == 'multivariate_gaussian':\n",
    "            seq = torch.nn.Sequential(decoder, Lambda(lambda x: x.view(x.shape[0], -1)))\n",
    "            self.decoder = DeepMultivariateNormal(seq, np.prod(self.img_shape), np.prod(self.img_shape))\n",
    "        elif self.decoder_type == 'sharedvar_multivariate_gaussian':\n",
    "            seq = torch.nn.Sequential(decoder, Lambda(lambda x: x.view(x.shape[0], -1)))\n",
    "            self.decoder = DeepMultivariateNormal(seq, np.prod(self.img_shape), np.prod(self.img_shape))\n",
    "\n",
    "            torch.nn.init.zeros_(self.decoder.logdiag_head.weight)\n",
    "            self.decoder.logdiag_head.weight.requires_grad = False\n",
    "\n",
    "            torch.nn.init.zeros_(self.decoder.lower_head.weight)\n",
    "            self.decoder.lower_head.weight.requires_grad = False\n",
    "\n",
    "            torch.nn.init.normal_(self.decoder.logdiag_head.bias, self.logstd_init, 1e-1)\n",
    "            self.decoder.logdiag_head.bias.requires_grad = True\n",
    "        elif self.decoder_type == 'lowrank_multivariate_gaussian':\n",
    "            seq = torch.nn.Sequential(decoder, Lambda(lambda x: x.view(x.shape[0], -1)))\n",
    "            self.decoder = DeepLowRankMultivariateNormal(seq, np.prod(self.img_shape), np.prod(self.img_shape), decoder_cov_rank)\n",
    "        elif self.decoder_type == 'sharedvar_lowrank_multivariate_gaussian':\n",
    "            seq = torch.nn.Sequential(decoder, Lambda(lambda x: x.view(x.shape[0], -1)))\n",
    "            self.decoder = DeepLowRankMultivariateNormal(seq, np.prod(self.img_shape), np.prod(self.img_shape), decoder_cov_rank)\n",
    "\n",
    "            torch.nn.init.zeros_(self.decoder.logdiag_head.weight)\n",
    "            self.decoder.logdiag_head.weight.requires_grad = False\n",
    "\n",
    "            torch.nn.init.zeros_(self.decoder.factor_head.weight)\n",
    "            self.decoder.factor_head.weight.requires_grad = False\n",
    "\n",
    "            torch.nn.init.normal_(self.decoder.logdiag_head.bias, self.logstd_init, 1e-1)\n",
    "            self.decoder.logdiag_head.bias.requires_grad = True\n",
    "        else:\n",
    "            raise ValueError(f'unknown decoder type {self.decoder_type}.')\n",
    "        \n",
    "        # encoder parts \n",
    "        self.encoder = Encoder(\n",
    "            num_convolutions=self.num_convolutions, \n",
    "            filters=self.enc_filters, \n",
    "            latent_dim=self.latent_dim, \n",
    "            input_size=self.img_shape\n",
    "            )\n",
    "        \n",
    "        latent_layers = torch.nn.Sequential(torch.nn.Linear(self.latent_dim + self.context_dim, self.latent_dim), torch.nn.ReLU())\n",
    "        self.latent_encoder = DeepIndepNormal(latent_layers, self.latent_dim, self.latent_dim)\n",
    "\n",
    "        # Priors\n",
    "        # priors for discrete variables \n",
    "        self.sex_logits = torch.nn.Parameter(torch.zeros([1, ])) \n",
    "\n",
    "        self.register_buffer('slice_number_min', torch.zeros([1, ], requires_grad=False))\n",
    "        self.register_buffer('slice_number_max', 12.*torch.ones([1, ], requires_grad=False)+1.)\n",
    "\n",
    "        self.register_buffer('apoE_min', torch.zeros([1, ], requires_grad=False))\n",
    "        self.register_buffer('apoE_max', 3.*torch.ones([1, ], requires_grad=False)+1.)\n",
    "\n",
    "        # priors for continuous variables - note base and flow priors \n",
    "        for k in self.required_data - {'x', 'PTGENDER', 'APOE4', 'slice_number'}:  \n",
    "            self.register_buffer(f'{k}_base_loc', torch.zeros([1, ], requires_grad=False))\n",
    "            self.register_buffer(f'{k}_base_scale', torch.ones([1, ], requires_grad=False)) \n",
    "        \n",
    "        for k in self.required_data - {'sex', 'x', 'slice_number'}:\n",
    "            self.register_buffer(f'{k}_flow_lognorm_loc', torch.zeros([], requires_grad=False))\n",
    "            self.register_buffer(f'{k}_flow_lognorm_scale', torch.ones([], requires_grad=False))\n",
    "\n",
    "        # image prior \n",
    "        self.register_buffer('x_base_loc', torch.zeros(self.img_shape, requires_grad=False))\n",
    "        self.register_buffer('x_base_scale', torch.ones(self.img_shape, requires_grad=False))\n",
    "\n",
    "        # latent space prior \n",
    "        self.register_buffer('z_loc', torch.zeros([latent_dim, ], requires_grad=False))\n",
    "        self.register_buffer('z_scale', torch.ones([latent_dim, ], requires_grad=False))\n",
    "        \n",
    "        # flows \n",
    "\n",
    "        # age flow \n",
    "        self.age_flow_components = ComposeTransformModule([Spline(1)])\n",
    "        self.age_flow_lognorm = AffineTransform(loc=self.age_flow_lognorm_loc.item(), scale=self.age_flow_lognorm_scale.item())\n",
    "        self.age_flow_constraint_transforms = ComposeTransform([self.age_flow_lognorm, ExpTransform()])\n",
    "        self.age_flow_transforms = ComposeTransform([self.age_flow_components, self.age_flow_constraint_transforms])\n",
    "\n",
    "        # tau flow \n",
    "        self.tau_flow_components = ComposeTransformModule([Spline(1)])\n",
    "        self.tau_flow_lognorm = AffineTransform(loc=self.tau_flow_lognorm_loc.item(), scale=self.tau_flow_lognorm_scale.item())\n",
    "        self.tau_flow_constraint_transforms = ComposeTransform([self.tau_flow_lognorm, ExpTransform()])\n",
    "        self.tau_flow_transforms = ComposeTransform([self.tau_flow_components, self.tau_flow_constraint_transforms])\n",
    "\n",
    "        # education flow \n",
    "        self.education_flow_components = ComposeTransformModule([Spline(1)])\n",
    "        self.education_flow_lognorm = AffineTransform(loc=self.education_flow_lognorm_loc.item(), scale=self.education_flow_lognorm_scale.item())\n",
    "        self.education_flow_constraint_transforms = ComposeTransform([self.education_flow_lognorm, ExpTransform()])\n",
    "        self.education_flow_transforms = ComposeTransform([self.education_flow_components, self.education_flow_constraint_transforms])\n",
    "\n",
    "        # other flows shared components \n",
    "        # all flows require an affine normalisation and exponentiation transformation \n",
    "        self.ventricle_volume_flow_lognorm = AffineTransform(loc=self.ventricle_volume_flow_lognorm_loc.item(), scale=self.ventricle_volume_flow_lognorm_scale.item())  # noqa: E501\n",
    "        self.ventricle_volume_flow_constraint_transforms = ComposeTransform([self.ventricle_volume_flow_lognorm, ExpTransform()])\n",
    "\n",
    "        self.brain_volume_flow_lognorm = AffineTransform(loc=self.brain_volume_flow_lognorm_loc.item(), scale=self.brain_volume_flow_lognorm_scale.item())\n",
    "        self.brain_volume_flow_constraint_transforms = ComposeTransform([self.brain_volume_flow_lognorm, ExpTransform()])    \n",
    "\n",
    "        self.av45_flow_lognorm = AffineTransform(loc=self.av45_flow_lognorm_loc.item(), scale=self.av45_flow_lognorm_scale.item())\n",
    "        self.av45_flow_eps = AffineTransform(loc=-eps, scale=1.) # adding some noise as per the MS implementation\n",
    "        self.av45_flow_constraint_transforms = ComposeTransform([self.av45_flow_lognorm, ExpTransform(), self.av45_flow_eps]) \n",
    "\n",
    "        self.moca_flow_lognorm = AffineTransform(loc=self.moca_flow_lognorm_loc.item(), scale=self.moca_flow_lognorm_scale.item())\n",
    "        self.moca_flow_eps = AffineTransform(loc=-eps, scale=1.)\n",
    "        self.moca_flow_constraint_transforms = ComposeTransform([self.moca_flow_lognorm, ExpTransform(), self.moca_flow_eps])\n",
    "    \n",
    "    def __setattr__(self, name, value):\n",
    "        super().__setattr__(name, value)\n",
    "\n",
    "        if 'flow_lognorm_loc' in name:\n",
    "            name_ = name.replace('flow_lognorm_loc', '')\n",
    "            getattr(self, name_ + 'flow_lognorm').loc = value.item()\n",
    "        elif 'flow_lognorm_scale' in name:\n",
    "            name_ = name.replace('flow_lognorm_scale', '')\n",
    "            getattr(self, name_ + 'flow_lognorm').scale = value.item()\n",
    "    \n",
    "    def _get_preprocess_transforms(self):\n",
    "        return super()._get_preprocess_transforms().inv\n",
    "    \n",
    "    def _get_transformed_x_dist(self, latent):\n",
    "        x_pred_dist = self.decoder.predict(latent) # returns a normal distribution with mean of the predicted image \n",
    "        x_base_dist = Normal(self.x_base_loc, self.x_base_scale).to_event(3) # 3 dimensions starting from right dep. \n",
    "\n",
    "        preprocess_transform = self._get_preprocess_transforms()\n",
    "\n",
    "        if isinstance(x_pred_dist, MultivariateNormal) or isinstance(x_pred_dist, LowRankMultivariateNormal):\n",
    "            chol_transform = LowerCholeskyAffine(x_pred_dist.loc, x_pred_dist.scale_tril)\n",
    "            reshape_transform = ReshapeTransform(self.img_shape, (np.prod(self.img_shape), ))\n",
    "            x_reparam_transform = ComposeTransform([reshape_transform, chol_transform, reshape_transform.inv])\n",
    "        elif isinstance(x_pred_dist, Independent):\n",
    "            x_pred_dist = x_pred_dist.base_dist\n",
    "            x_reparam_transform = AffineTransform(x_pred_dist.loc, x_pred_dist.scale, 3)\n",
    "        else:\n",
    "            raise ValueError(f'{x_pred_dist} not valid.')\n",
    "\n",
    "        return TransformedDistribution(x_base_dist, ComposeTransform([x_reparam_transform, preprocess_transform]))\n",
    "\n",
    "    @pyro_method\n",
    "    def guide(self, obs):\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    @pyro_method\n",
    "    def svi_guide(self, obs):\n",
    "        self._check_observation(obs)\n",
    "        self.guide(obs)\n",
    "    \n",
    "    @pyro_method \n",
    "    def svi_model(self, obs):\n",
    "        self._check_observation(obs)\n",
    "        batch_size = obs['x'].shape[0]\n",
    "        with pyro.plate('observations', batch_size):\n",
    "            pyro.condition(self.model, data=obs)()\n",
    "    \n",
    "    @pyro_method\n",
    "    def infer_z(self, *args, **kwargs):\n",
    "        return self.guide(*args, **kwargs)\n",
    "    \n",
    "    @property\n",
    "    def required_data(self):\n",
    "        return {'x', 'sex', 'age', 'ventricle_volume', 'brain_volume', 'ptau', 'av45', \n",
    "        'MOCA', 'education', 'APOE4', 'slice_number'}\n",
    "\n",
    "    def _check_observation(self, obs):\n",
    "        keys = obs.keys()\n",
    "        assert self.required_data == set(keys), f'Incompatible observation: {tuple(keys)}' \n",
    "    \n",
    "    @pyro_method \n",
    "    def infer(self, **obs): \n",
    "        self._check_observation(obs)\n",
    "        \n",
    "        obs_ = obs.copy()\n",
    "        \n",
    "        z = self.infer(obs_)\n",
    "        obs_.update(dict(z=z))\n",
    "        \n",
    "        exogenous = self.infer_exogeneous(obs_)\n",
    "        exogenous['z'] = z\n",
    "\n",
    "        return exogenous\n",
    "    \n",
    "    @pyro_method\n",
    "    def reconstruct(self, obs, num_particles:int=1): \n",
    "        self._check_observation(obs)\n",
    "\n",
    "        z_dist = pyro.poutine.trace(self.guide).get_trace(obs).nodes['z']['fn']\n",
    "\n",
    "        batch_size = obs['x'].shape[0]\n",
    "        obs_ = {k: v for k, v in obs.items() if k != 'x'}\n",
    "\n",
    "        recons = []\n",
    "        for _ in range(num_particles): \n",
    "            z = pyro.sample('z', z_dist) \n",
    "            obs_.update({'z': z})\n",
    "            recon, *_ = pyro.poutine.condition(\n",
    "                self.sample, data=obs_)(batch_size)\n",
    "            recons += [recon]\n",
    "        return torch.stack(recons).mean(0)\n",
    "\n",
    "    def _cf_dict(self, counterfactuals):\n",
    "        out = {k: [] for k in self.required_data}\n",
    "        for cf in counterfactuals:\n",
    "            for k in self.required_data:\n",
    "                out[k].append(cf[k])\n",
    "        out = {k: torch.stack(v).mean(0) for k, v in out.items()}\n",
    "        return out\n",
    "\n",
    "    @pyro_method\n",
    "    def counterfactual(self, obs, condition: Mapping = None, num_particles: int = 1): \n",
    "        self._check_observation(obs)\n",
    "        obs_ = obs.copy()\n",
    "\n",
    "        z_dist = pyro.poutine.trace(self.guide).get_trace(obs_).nodes['z']['fn'] # variational posterior\n",
    "        n = obs_['x'].shape[0]\n",
    "\n",
    "        counterfactuals = []\n",
    "        for _ in range(num_particles): \n",
    "            z = pyro.sample('z', z_dist)\n",
    "            obs_.update(dict(z=z))\n",
    "            exogenous = self.infer_exogeneous(obs_)\n",
    "            exogenous['z'] = z\n",
    "            # condition on these variables if they aren't included in 'do' as they are root nodes \n",
    "            # and we don't have the exogenous noise for them yet \n",
    "            if 'sex' not in condition.keys(): \n",
    "                exogenous['sex'] = obs_['sex']\n",
    "            if 'slice_number' not in condition.keys(): \n",
    "                exogenous['slice_number'] = obs_['slice_number']\n",
    "            if 'APOE4' not in condition.keys(): \n",
    "                exogenous['APOE4'] = obs_['APOE4']\n",
    "            \n",
    "            counter = pyro.poutine.do(pyro.poutine.condition(self.sample_scm, data=exogenous), data=condition)(n)\n",
    "            counterfactuals += [counter]\n",
    "        \n",
    "        return self._cf_dict(counterfactuals)\n",
    "    \n",
    "    @classmethod\n",
    "    def add_arguments(cls, parser):\n",
    "        parser = super().add_arguments(parser)\n",
    "\n",
    "        parser.add_argument('--latent_dim', default=100, type=int, help=\"latent dimension of model (default: %(default)s)\")\n",
    "        parser.add_argument('--logstd_init', default=-5, type=float, help=\"init of logstd (default: %(default)s)\")\n",
    "        parser.add_argument('--enc_filters', default='16,24,32,64,128', type=str, help=\"number of filters to use (default: %(default)s)\")\n",
    "        parser.add_argument('--dec_filters', default='128,64,32,24,16', type=str, help=\"number of filters to use (default: %(default)s)\")\n",
    "        parser.add_argument('--num_convolutions', default=3, type=int, help=\"number of convolutions to build model (default: %(default)s)\")\n",
    "        parser.add_argument('--use_upconv', default=False, action='store_true', help=\"toogle upconv (default: %(default)s)\")\n",
    "        parser.add_argument(\n",
    "            '--decoder_type', default='fixed_var', help=\"var type (default: %(default)s)\",\n",
    "            choices=['fixed_var', 'learned_var', 'independent_gaussian', 'sharedvar_multivariate_gaussian', 'multivariate_gaussian',\n",
    "                     'sharedvar_lowrank_multivariate_gaussian', 'lowrank_multivariate_gaussian'])\n",
    "        parser.add_argument('--decoder_cov_rank', default=10, type=int, help=\"rank for lowrank cov approximation (requires lowrank decoder) (default: %(default)s)\")  # noqa: E501\n",
    "\n",
    "        return parser\n",
    "    \n",
    "class SVIExperiment(BaseCovariateExperiment):\n",
    "    def __init__(self, hparams, pyro_model: BaseSEM):\n",
    "        super().__init__(hparams, pyro_model)\n",
    "\n",
    "        self.svi_loss = CustomELBO(num_particles=hparams.num_svi_particles)\n",
    "\n",
    "        self._build_svi()\n",
    "    \n",
    "    def _build_svi(self, loss=None):\n",
    "        def per_param_callable(module_name, param_name):\n",
    "            params = {'eps': 1e-5, 'amsgrad': self.hparams.use_amsgrad, 'weight_decay': self.hparams.l2}\n",
    "            if 'flow_components' in module_name or 'sex_logits' in param_name:\n",
    "                params['lr'] = self.hparams.pgm_lr\n",
    "            else:\n",
    "                params['lr'] = self.hparams.lr\n",
    "\n",
    "            print(f'building opt for {module_name} - {param_name} with p: {params}')\n",
    "            return params\n",
    "\n",
    "        if loss is None:\n",
    "            loss = self.svi_loss\n",
    "\n",
    "        if self.hparams.use_cf_guide:\n",
    "            def guide(*args, **kwargs):\n",
    "                return self.pyro_model.counterfactual_guide(*args, **kwargs, counterfactual_type=self.hparams.cf_elbo_type)\n",
    "            self.svi = SVI(self.pyro_model.svi_model, guide, Adam(per_param_callable), loss)\n",
    "        else:\n",
    "            self.svi = SVI(self.pyro_model.svi_model, self.pyro_model.svi_guide, Adam(per_param_callable), loss)\n",
    "        self.svi.loss_class = loss\n",
    "    \n",
    "    def backward(self, *args, **kwargs):\n",
    "        pass  # No loss to backpropagate since we're using Pyro's optimisation machinery\n",
    "\n",
    "    def print_trace_updates(self, batch):\n",
    "        with torch.no_grad():\n",
    "            print('Traces:\\n' + ('#' * 10))\n",
    "\n",
    "            guide_trace = pyro.poutine.trace(self.pyro_model.svi_guide).get_trace(**batch)\n",
    "            model_trace = pyro.poutine.trace(pyro.poutine.replay(self.pyro_model.svi_model, trace=guide_trace)).get_trace(**batch)\n",
    "\n",
    "            guide_trace = pyro.poutine.util.prune_subsample_sites(guide_trace)\n",
    "            model_trace = pyro.poutine.util.prune_subsample_sites(model_trace)\n",
    "\n",
    "            model_trace.compute_log_prob()\n",
    "            guide_trace.compute_score_parts()\n",
    "\n",
    "            print(f'model: {model_trace.nodes.keys()}')\n",
    "            for name, site in model_trace.nodes.items():\n",
    "                if site[\"type\"] == \"sample\":\n",
    "                    fn = site['fn']\n",
    "                    if isinstance(fn, Independent):\n",
    "                        fn = fn.base_dist\n",
    "                    print(f'{name}: {fn} - {fn.support}')\n",
    "                    log_prob_sum = site[\"log_prob_sum\"]\n",
    "                    is_obs = site[\"is_observed\"]\n",
    "                    print(f'model - log p({name}) = {log_prob_sum} | obs={is_obs}')\n",
    "                    if torch.isnan(log_prob_sum):\n",
    "                        value = site['value'][0]\n",
    "                        conc0 = fn.concentration0\n",
    "                        conc1 = fn.concentration1\n",
    "\n",
    "                        print(f'got:\\n{value}\\n{conc0}\\n{conc1}')\n",
    "\n",
    "                        raise Exception()\n",
    "\n",
    "            print(f'guide: {guide_trace.nodes.keys()}')\n",
    "\n",
    "            for name, site in guide_trace.nodes.items():\n",
    "                if site[\"type\"] == \"sample\":\n",
    "                    fn = site['fn']\n",
    "                    if isinstance(fn, Independent):\n",
    "                        fn = fn.base_dist\n",
    "                    print(f'{name}: {fn} - {fn.support}')\n",
    "                    entropy = site[\"score_parts\"].entropy_term.sum()\n",
    "                    is_obs = site[\"is_observed\"]\n",
    "                    print(f'guide - log q({name}) = {entropy} | obs={is_obs}')\n",
    "    \n",
    "    def get_trace_metrics(self, batch): \n",
    "        metrics = {}\n",
    "\n",
    "        model = self.svi.loss_class.trace_storage['model']\n",
    "        guide = self.svi.loss_class.trace_storage['guide']\n",
    "\n",
    "        for k in self.required_data: \n",
    "            metrics[f'log p({k})'] = model.nodes[k]['log_prob'].mean()\n",
    "        \n",
    "        metrics['p(z)'] = model.nodes['z']['log_prob'].mean()\n",
    "        metrics['q(z)'] = guide.nodes['z']['log_prob'].mean()\n",
    "        metrics['log p(z) - log q(z)'] = metrics['p(z)'] - metrics['q(z)']\n",
    "\n",
    "        return metrics \n",
    "    \n",
    "    # can come back and add noise per Their 2016 - check MS implementation for this. \n",
    "    \n",
    "    def prep_batch(self, batch):\n",
    "        x = 255. * batch['image'].float()  # multiply by 255 b/c preprocess tfms\n",
    "        out = dict(x=x)\n",
    "        for k in self.required_data:\n",
    "            if k in batch:\n",
    "                out[k] = batch[k].unsqueeze(1).float()\n",
    "\n",
    "        if self.training: \n",
    "            out['x'] += (torch.rand_like(out['x']) - 0.5)\n",
    "        \n",
    "        return out \n",
    "    \n",
    "    def training_step(self, batch, batch_idx): \n",
    "        batch = self.prep_batch(batch)\n",
    "\n",
    "        if self.hparams.validate: \n",
    "            print('Validation:')\n",
    "            self.print_trace_updates(batch)\n",
    "        \n",
    "        loss = self.svi.step(**batch)\n",
    "\n",
    "        metrics = self.get_trace_metrics(batch)\n",
    "\n",
    "        if np.isnan(loss):\n",
    "            self.logger.experiment.add_text('nan', f'nand at {self.current_epoch}:\\n{metrics}')\n",
    "            raise ValueError('loss went to nan with metrics:\\n{}'.format(metrics))\n",
    "        \n",
    "        tensorboard_logs = {('train/' + k): v for k, v in metrics.items()}\n",
    "        tensorboard_logs['train/loss'] = loss\n",
    "\n",
    "        self.log_dict(tensorboard_logs)\n",
    "\n",
    "        return torch.Tensor([loss])\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        batch = self.prep_batch(batch)\n",
    "\n",
    "        loss = self.svi.evaluate_loss(**batch)\n",
    "\n",
    "        metrics = self.get_trace_metrics(batch)\n",
    "\n",
    "        return {'loss': loss, **metrics}\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        batch = self.prep_batch(batch)\n",
    "\n",
    "        loss = self.svi.evaluate_loss(**batch)\n",
    "\n",
    "        metrics = self.get_trace_metrics(batch)\n",
    "\n",
    "        samples = self.build_test_samples(batch)\n",
    "\n",
    "        return {'loss': loss, **metrics, 'samples': samples}\n",
    "    \n",
    "    @classmethod\n",
    "    def add_arguments(cls, parser):\n",
    "        parser = super().add_arguments(parser)\n",
    "\n",
    "        parser.add_argument('--num_svi_particles', default=4, type=int, help=\"number of particles to use for ELBO (default: %(default)s)\")\n",
    "        parser.add_argument('--num_sample_particles', default=32, type=int, help=\"number of particles to use for MC sampling (default: %(default)s)\")\n",
    "        parser.add_argument('--use_cf_guide', default=False, action='store_true', help=\"whether to use counterfactual guide (default: %(default)s)\")\n",
    "        parser.add_argument(\n",
    "            '--cf_elbo_type', default=-1, choices=[-1, 0, 1, 2],\n",
    "            help=\"-1: randomly select per batch, 0: shuffle thickness, 1: shuffle intensity, 2: shuffle both (default: %(default)s)\")\n",
    "\n",
    "        return parser\n",
    "    \n",
    "EXPERIMENT_REGISTRY[SVIExperiment.__name__] = SVIExperiment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('dscm')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "142ccf925348e6e849eb5106808af40cbad73a6d9b4e62251197a482f88424bd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
